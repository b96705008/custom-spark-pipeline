{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sc \\\n",
    "    .parallelize([(1, 'b', 'A'), (2, 'a', 'B'), (3, 'b', 'B'), (4, 'c', None), (5, 'd', 'B')]) \\\n",
    "    .toDF([\"id\", \"x1\", 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "| id| x1|  x2|\n",
      "+---+---+----+\n",
      "|  1|  b|   A|\n",
      "|  2|  a|   B|\n",
      "|  3|  b|   B|\n",
      "|  4|  c|null|\n",
      "|  5|  d|   B|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test String Indexer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='x1', outputCol='x1_indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = indexer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'b', u'a', u'c', u'd']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+\n",
      "| id| x1|  x2|x1_indexed|\n",
      "+---+---+----+----------+\n",
      "|  1|  b|   A|       0.0|\n",
      "|  2|  a|   B|       1.0|\n",
      "|  3|  b|   B|       0.0|\n",
      "|  4|  c|null|       2.0|\n",
      "|  5|  d|   B|       3.0|\n",
      "+---+---+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer2 = StringIndexer(inputCol='x2', outputCol='x2_indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = indexer2.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexer_4e118e929f2f814d5362"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'B', u'A']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model2.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer3 = StringIndexer(inputCol='x2', outputCol='x2_indexed', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = indexer3.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'B', u'A']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+\n",
      "| id| x1|  x2|x2_indexed|\n",
      "+---+---+----+----------+\n",
      "|  1|  b|   A|       1.0|\n",
      "|  2|  a|   B|       0.0|\n",
      "|  3|  b|   B|       0.0|\n",
      "|  4|  c|null|       2.0|\n",
      "|  5|  d|   B|       0.0|\n",
      "+---+---+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'B', u'A']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer4 = StringIndexer(inputCol='x2', outputCol='x2_indexed', handleInvalid='skip')\n",
    "model4 = indexer4.fit(df)\n",
    "model4.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----------+\n",
      "| id| x1| x2|x2_indexed|\n",
      "+---+---+---+----------+\n",
      "|  1|  b|  A|       1.0|\n",
      "|  2|  a|  B|       0.0|\n",
      "|  3|  b|  B|       0.0|\n",
      "|  5|  d|  B|       0.0|\n",
      "+---+---+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Indexer + One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorAssembler\n",
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stages = [\n",
    "    StringIndexer(inputCol='x1', outputCol='x1_indexed'),\n",
    "    StringIndexer(inputCol='x2', outputCol='x2_indexed', handleInvalid='keep'),\n",
    "    OneHotEncoderEstimator(inputCols=['x1_indexed', 'x2_indexed'], outputCols=['x1_encoded', 'x2_encoded'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_model = Pipeline(stages=stages).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_4a26a9f18cb528f781c1,\n",
       " StringIndexer_4e5e8dc95f6e51a21a74,\n",
       " OneHotEncoderEstimator_49ae97766c3ab4de2b8c]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'b', u'a', u'c', u'd'], [u'B', u'A'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages[0].labels, pipeline_model.stages[1].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "| id| x1|  x2|x1_indexed|x2_indexed|   x1_encoded|   x2_encoded|\n",
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "|  1|  b|   A|       0.0|       1.0|(3,[0],[1.0])|(2,[1],[1.0])|\n",
      "|  2|  a|   B|       1.0|       0.0|(3,[1],[1.0])|(2,[0],[1.0])|\n",
      "|  3|  b|   B|       0.0|       0.0|(3,[0],[1.0])|(2,[0],[1.0])|\n",
      "|  4|  c|null|       2.0|       2.0|(3,[2],[1.0])|    (2,[],[])|\n",
      "|  5|  d|   B|       3.0|       0.0|    (3,[],[])|(2,[0],[1.0])|\n",
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stages2 = [\n",
    "    StringIndexer(inputCol='x1', outputCol='x1_indexed'),\n",
    "    StringIndexer(inputCol='x2', outputCol='x2_indexed', handleInvalid='keep'),\n",
    "    OneHotEncoderEstimator(inputCols=['x1_indexed', 'x2_indexed'], \n",
    "                           outputCols=['x1_encoded', 'x2_encoded'],\n",
    "                           dropLast=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_model2 = Pipeline(stages=stages2).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "| id| x1|  x2|x1_indexed|x2_indexed|   x1_encoded|   x2_encoded|\n",
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "|  1|  b|   A|       0.0|       1.0|(4,[0],[1.0])|(3,[1],[1.0])|\n",
      "|  2|  a|   B|       1.0|       0.0|(4,[1],[1.0])|(3,[0],[1.0])|\n",
      "|  3|  b|   B|       0.0|       0.0|(4,[0],[1.0])|(3,[0],[1.0])|\n",
      "|  4|  c|null|       2.0|       2.0|(4,[2],[1.0])|(3,[2],[1.0])|\n",
      "|  5|  d|   B|       3.0|       0.0|(4,[3],[1.0])|(3,[0],[1.0])|\n",
      "+---+---+----+----------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_model2.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stages2 = [\n",
    "    StringIndexer(inputCol='x1', outputCol='x1_indexed'),\n",
    "    StringIndexer(inputCol='x2', outputCol='x2_indexed', handleInvalid='skip'),\n",
    "    OneHotEncoderEstimator(inputCols=['x1_indexed', 'x2_indexed'], \n",
    "                           outputCols=['x1_encoded', 'x2_encoded'],\n",
    "                           dropLast=False),\n",
    "    VectorAssembler(inputCols=['x1_encoded', 'x2_encoded'], outputCol='features')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_model3 = Pipeline(stages=stages2).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pipeline_model3.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----------+----------+-------------+-------------+-------------------+\n",
      "| id| x1| x2|x1_indexed|x2_indexed|   x1_encoded|   x2_encoded|           features|\n",
      "+---+---+---+----------+----------+-------------+-------------+-------------------+\n",
      "|  1|  b|  A|       0.0|       1.0|(4,[0],[1.0])|(2,[1],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|  2|  a|  B|       1.0|       0.0|(4,[1],[1.0])|(2,[0],[1.0])|(6,[1,4],[1.0,1.0])|\n",
      "|  3|  b|  B|       0.0|       0.0|(4,[0],[1.0])|(2,[0],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|  5|  d|  B|       3.0|       0.0|(4,[3],[1.0])|(2,[0],[1.0])|(6,[3,4],[1.0,1.0])|\n",
      "+---+---+---+----------+----------+-------------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Spark Dataframe to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'is_x1_b', u'is_x1_a', u'is_x1_c', u'is_x1_d', u'is_x2_B', u'is_x2_A']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['x1', 'x2']\n",
    "cate_feature_names = []\n",
    "\n",
    "for n, s in zip(feature_names, pipeline_model3.stages[:2]):\n",
    "    names = map(lambda l: 'is_{}_{}'.format(n, l), s.labels)\n",
    "    cate_feature_names.extend(names)\n",
    "    \n",
    "cate_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(field, r):\n",
    "    return np.expand_dims(r[field], axis=0)\n",
    "\n",
    "def merge_features(field, d1, d2):\n",
    "    return np.concatenate([d1, d2])\n",
    "\n",
    "def map_spark_features_to_pandas(col_names, field, feature_df):\n",
    "    map_func = functools.partial(transform_features, field)\n",
    "    reduce_func = functools.partial(merge_features, field)\n",
    "    features_array = feature_df.select(field).rdd \\\n",
    "        .map(map_func) \\\n",
    "        .reduce(reduce_func)\n",
    "    feature_pd = pd.DataFrame(data=features_array, columns=col_names)\n",
    "    return feature_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pd = map_spark_features_to_pandas(cate_feature_names, 'features', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_x1_b</th>\n",
       "      <th>is_x1_a</th>\n",
       "      <th>is_x1_c</th>\n",
       "      <th>is_x1_d</th>\n",
       "      <th>is_x2_B</th>\n",
       "      <th>is_x2_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_x1_b  is_x1_a  is_x1_c  is_x1_d  is_x2_B  is_x2_A\n",
       "0      1.0      0.0      0.0      0.0      0.0      1.0\n",
       "1      0.0      1.0      0.0      0.0      1.0      0.0\n",
       "2      1.0      0.0      0.0      0.0      1.0      0.0\n",
       "3      0.0      0.0      0.0      1.0      1.0      0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom String Indexing to OneHot in individual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml.pipeline import Estimator, Model, Pipeline, PipelineModel\n",
    "from pyspark.ml.param.shared import *\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a', u'c', u'b', u'd']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = 'x1'\n",
    "field_values = df.rdd.map(lambda x: x[field]).distinct().collect()\n",
    "field_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'a': 3, u'b': 0, u'c': 2, u'd': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = 'x1'\n",
    "field_values = df \\\n",
    "    .groupBy(field) \\\n",
    "    .agg(F.count('*').alias('count')) \\\n",
    "    .orderBy(F.desc('count')) \\\n",
    "    .rdd.map(lambda r: r[field]) \\\n",
    "    .collect()\n",
    "    \n",
    "index_map = {v: i for i, v in enumerate(field_values)}\n",
    "index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_row = df.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=1, x1=u'b', x2=u'A')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'b', [u'b', u'd', u'c', u'a'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[field], field_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(u'is_x1_b', 1.0),\n",
       "             (u'is_x1_d', 0.0),\n",
       "             (u'is_x1_c', 0.0),\n",
       "             (u'is_x1_a', 0.0)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_vals = [('is_{}_{}'.format(field, v), float(test_row[field]==v))\n",
    "               for v in field_values]\n",
    "onehot_dict = OrderedDict(onehot_vals)\n",
    "onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_x1_b\n",
      "is_x1_d\n",
      "is_x1_c\n",
      "is_x1_a\n"
     ]
    }
   ],
   "source": [
    "for k in onehot_dict: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(is_x1_a=0.0, is_x1_b=1.0, is_x1_c=0.0, is_x1_d=0.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Row(**onehot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HasOutputColsPrefix(Params):\n",
    "\n",
    "    output_prefix = Param(Params._dummy(), \"output_prefix\", \n",
    "                         \"prefix for every output column name\",\n",
    "                         typeConverter=TypeConverters.toString)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(HasOutputColsPrefix, self).__init__()\n",
    "        self._setDefault(output_prefix='is')\n",
    "    \n",
    "    def setOutputColsPrefix(self, value):\n",
    "        return self._set(output_prefix=value)\n",
    "\n",
    "    def getOutputColsPrefix(self):\n",
    "        return self.getOrDefault(self.output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HasFieldValues(Params):\n",
    "\n",
    "    field_values = Param(Params._dummy(), \"field_values\", \n",
    "                         \"all possible values for a field\",\n",
    "                         typeConverter=TypeConverters.toList)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(HasFieldValues, self).__init__()\n",
    "\n",
    "    def setFieldValues(self, value):\n",
    "        return self._set(field_values=value)\n",
    "\n",
    "    def getFieldValues(self):\n",
    "        return self.getOrDefault(self.field_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FillMode(Params):\n",
    "\n",
    "    fill_mode = Param(Params._dummy(), \"fill_mode\", \n",
    "                         \"should disassembler fill mode first\",\n",
    "                         typeConverter=TypeConverters.toBoolean)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FillMode, self).__init__()\n",
    "        self._setDefault(fill_mode=False)\n",
    "\n",
    "    def setFillMode(self, value):\n",
    "        return self._set(fill_mode=value)\n",
    "\n",
    "    def getFillMode(self):\n",
    "        return self.getOrDefault(self.fill_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringDisassembleModel(Model, HasInputCol, HasOutputCols, \n",
    "                             HasFieldValues, FillMode, \n",
    "                             DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    def getMode(self):\n",
    "        values = self.getFieldValues()\n",
    "        return None if len(values) == 0 else values[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def disassemble_row(params, row):\n",
    "        category = row[params['input']]\n",
    "        if category is None and params['fill_mode']:\n",
    "            category = params['mode']\n",
    "            \n",
    "        new_data = {f: float(category==v)\n",
    "                    for f, v in params['b_fv_list'].value}\n",
    "        \n",
    "        data = row.asDict()\n",
    "        data.update(new_data)\n",
    "        return Row(**data) \n",
    "    \n",
    "    def _transform(self, dataset):\n",
    "        fields = self.getOutputCols()\n",
    "        values = self.getFieldValues()\n",
    "        sc = dataset.rdd.context\n",
    "        b_fv_list = sc.broadcast(zip(fields, values))\n",
    "       \n",
    "        dismb_params = {\n",
    "            'input': self.getInputCol(),\n",
    "            'b_fv_list': sc.broadcast(zip(fields, values)),\n",
    "            'fill_mode': self.getFillMode(),\n",
    "            'mode': self.getMode()\n",
    "        }\n",
    "        \n",
    "        disassemble_func = functools \\\n",
    "            .partial(self.disassemble_row, dismb_params)\n",
    "        \n",
    "        cols = dataset.columns + fields\n",
    "        return dataset.rdd \\\n",
    "            .map(disassemble_func) \\\n",
    "            .toDF() \\\n",
    "            .select(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StringDisassembler(Estimator, HasInputCol, HasOutputColsPrefix, FillMode):\n",
    "    \n",
    "    def get_values(self, dataset):\n",
    "        x = self.getInputCol()\n",
    "        # values ordered by count (mode)\n",
    "        values = dataset \\\n",
    "            .where('{} is not null'.format(x)) \\\n",
    "            .groupBy(x) \\\n",
    "            .agg(F.count('*').alias('count')) \\\n",
    "            .orderBy(F.desc('count')) \\\n",
    "            .rdd.map(lambda r: r[x]) \\\n",
    "            .collect()\n",
    "            \n",
    "        return values\n",
    "    \n",
    "    def get_fields(self, values):\n",
    "        x = self.getInputCol()\n",
    "        prefix = self.getOutputColsPrefix()\n",
    "        return ['{}_{}_{}'.format(prefix, x, v) for v in values]\n",
    "    \n",
    "    def _fit(self, dataset):\n",
    "        x = self.getInputCol()\n",
    "        values = self.get_values(dataset)\n",
    "        fields = self.get_fields(values)\n",
    "        model = StringDisassembleModel() \\\n",
    "            .setInputCol(x) \\\n",
    "            .setOutputCols(fields) \\\n",
    "            .setFieldValues(values) \\\n",
    "            .setFillMode(self.getFillMode())\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "| id| x1|  x2|\n",
      "+---+---+----+\n",
      "|  1|  b|   A|\n",
      "|  2|  a|   B|\n",
      "|  3|  b|   B|\n",
      "|  4|  c|null|\n",
      "|  5|  d|   B|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+-------+-------+-------+\n",
      "| id| x1|  x2|is_x1_b|is_x1_d|is_x1_c|is_x1_a|\n",
      "+---+---+----+-------+-------+-------+-------+\n",
      "|  1|  b|   A|    1.0|    0.0|    0.0|    0.0|\n",
      "|  2|  a|   B|    0.0|    0.0|    0.0|    1.0|\n",
      "|  3|  b|   B|    1.0|    0.0|    0.0|    0.0|\n",
      "|  4|  c|null|    0.0|    0.0|    1.0|    0.0|\n",
      "|  5|  d|   B|    0.0|    1.0|    0.0|    0.0|\n",
      "+---+---+----+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StringDisassembler() \\\n",
    "    .setInputCol('x1') \\\n",
    "    .fit(df) \\\n",
    "    .transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+-------+\n",
      "| id| x1|  x2|is_x2_B|is_x2_A|\n",
      "+---+---+----+-------+-------+\n",
      "|  1|  b|   A|    0.0|    1.0|\n",
      "|  2|  a|   B|    1.0|    0.0|\n",
      "|  3|  b|   B|    1.0|    0.0|\n",
      "|  4|  c|null|    0.0|    0.0|\n",
      "|  5|  d|   B|    1.0|    0.0|\n",
      "+---+---+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StringDisassembler() \\\n",
    "    .setInputCol('x2') \\\n",
    "    .fit(df) \\\n",
    "    .transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+-------+\n",
      "| id| x1|  x2|is_x2_B|is_x2_A|\n",
      "+---+---+----+-------+-------+\n",
      "|  1|  b|   A|    0.0|    1.0|\n",
      "|  2|  a|   B|    1.0|    0.0|\n",
      "|  3|  b|   B|    1.0|    0.0|\n",
      "|  4|  c|null|    1.0|    0.0|\n",
      "|  5|  d|   B|    1.0|    0.0|\n",
      "+---+---+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disamb_model = StringDisassembler() \\\n",
    "    .setInputCol('x2') \\\n",
    "    .setFillMode(True) \\\n",
    "    .fit(df)\n",
    "\n",
    "disamb_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'B'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb_model.getMode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'is_x2_B', u'is_x2_A']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb_model.getOutputCols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disamb_pipeline = Pipeline(stages=[\n",
    "    StringDisassembler().setInputCol('x1'),\n",
    "    StringDisassembler().setInputCol('x2'),\n",
    "    StringDisassembler().setInputCol('x2').setOutputColsPrefix('fill_mode').setFillMode(True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disamb_pipeline_model = disamb_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "| id| x1|  x2|is_x1_b|is_x1_d|is_x1_c|is_x1_a|is_x2_B|is_x2_A|fill_mode_x2_B|fill_mode_x2_A|\n",
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "|  1|  b|   A|    1.0|    0.0|    0.0|    0.0|    0.0|    1.0|           0.0|           1.0|\n",
      "|  2|  a|   B|    0.0|    0.0|    0.0|    1.0|    1.0|    0.0|           1.0|           0.0|\n",
      "|  3|  b|   B|    1.0|    0.0|    0.0|    0.0|    1.0|    0.0|           1.0|           0.0|\n",
      "|  4|  c|null|    0.0|    0.0|    1.0|    0.0|    0.0|    0.0|           1.0|           0.0|\n",
      "|  5|  d|   B|    0.0|    1.0|    0.0|    0.0|    1.0|    0.0|           1.0|           0.0|\n",
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disamb_pipeline_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disamb_pipeline_model.write().overwrite().save('tmp/onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_pipeline_model = PipelineModel.load('tmp/onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "| id| x1|  x2|is_x1_b|is_x1_d|is_x1_c|is_x1_a|is_x2_B|is_x2_A|fill_mode_x2_B|fill_mode_x2_A|\n",
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "|  1|  b|   A|    1.0|    0.0|    0.0|    0.0|    0.0|    1.0|           0.0|           1.0|\n",
      "|  2|  a|   B|    0.0|    0.0|    0.0|    1.0|    1.0|    0.0|           1.0|           0.0|\n",
      "|  3|  b|   B|    1.0|    0.0|    0.0|    0.0|    1.0|    0.0|           1.0|           0.0|\n",
      "|  4|  c|null|    0.0|    0.0|    1.0|    0.0|    0.0|    0.0|           1.0|           0.0|\n",
      "|  5|  d|   B|    0.0|    1.0|    0.0|    0.0|    1.0|    0.0|           1.0|           0.0|\n",
      "+---+---+----+-------+-------+-------+-------+-------+-------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
