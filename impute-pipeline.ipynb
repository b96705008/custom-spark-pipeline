{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Estimator, Model, Pipeline, PipelineModel\n",
    "from pyspark.ml.param.shared import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.util import JavaMLReadable, JavaMLWritable, DefaultParamsReadable, DefaultParamsWritable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.95.160:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Jupyter_Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10f2afb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Categorical Features with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasModeDict(Params):\n",
    "\n",
    "    mode_dict = Param(Params._dummy(),\n",
    "            \"mode_dict\", \"mode for every column\")\n",
    "\n",
    "    def __init__(self):\n",
    "        super(HasModeDict, self).__init__()\n",
    "\n",
    "    def setModeDict(self, value):\n",
    "        return self._set(mode_dict=value)\n",
    "\n",
    "    def getModeDict(self):\n",
    "        return self.getOrDefault(self.mode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeCategoricalWithModeModel(Model, HasInputCols, HasOutputCols, HasModeDict, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    def _transform(self, dataset):\n",
    "        xs = self.getInputCols()\n",
    "        ys = self.getOutputCols()\n",
    "        mode_dict = self.getModeDict()\n",
    "        imputed_df = dataset\n",
    "        for x, y in zip(xs, ys):\n",
    "            imputed_df = imputed_df \\\n",
    "                .withColumn(y, F.when(F.col(x).isNull(), mode_dict[x]).otherwise(F.col(x)))\n",
    "        return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImputeCategoricalWithMode(Estimator, HasInputCols, HasOutputCols):\n",
    "    \n",
    "    def prepare_io_params(self):\n",
    "        xs = self.getInputCols()\n",
    "        ys = []\n",
    "        try:\n",
    "            ys = self.getOutputCols()\n",
    "        except:\n",
    "            ys = []\n",
    "        n = len(xs) - len(ys)\n",
    "        if n > 0:\n",
    "            ys = ys[:] + xs[-n:]\n",
    "        elif n < 0:\n",
    "            ys = ys[:n]\n",
    "        return xs, ys\n",
    "    \n",
    "    def _fit(self, dataset):\n",
    "        xs, ys = self.prepare_io_params()\n",
    "        mode_dict = {}\n",
    "        for c in xs:\n",
    "            rows = df.where('{} is not null'.format(c)) \\\n",
    "                .groupBy(c) \\\n",
    "                .agg(F.count('*').alias('count')) \\\n",
    "                .orderBy(F.desc('count')) \\\n",
    "                .take(1) \n",
    "            if len(rows) > 0:\n",
    "                mode_dict[c] = rows[0][c]\n",
    "        impute_model = ImputeCategoricalWithModeModel() \\\n",
    "            .setInputCols(xs) \\\n",
    "            .setOutputCols(ys) \\\n",
    "            .setModeDict(mode_dict)\n",
    "            \n",
    "        return impute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc \\\n",
    "    .parallelize([(1, 'a', 'A'), (2, 'a', 'B'), (3, 'b', 'B'), (4, 'c', None), (4, None, 'B')]) \\\n",
    "    .toDF([\"id\", \"x1\", 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+\n",
      "| id|  x1|  x2|\n",
      "+---+----+----+\n",
      "|  1|   a|   A|\n",
      "|  2|   a|   B|\n",
      "|  3|   b|   B|\n",
      "|  4|   c|null|\n",
      "|  4|null|   B|\n",
      "+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_mode = ImputeCategoricalWithMode() \\\n",
    "    .setInputCols(['x1', 'x2']) \\\n",
    "    .setOutputCols(['x1_im', 'x2_im'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_model = impute_mode.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+-----+-----+\n",
      "| id|  x1|  x2|x1_im|x2_im|\n",
      "+---+----+----+-----+-----+\n",
      "|  1|   a|   A|    a|    A|\n",
      "|  2|   a|   B|    a|    B|\n",
      "|  3|   b|   B|    b|    B|\n",
      "|  4|   c|null|    c|    B|\n",
      "|  4|null|   B|    a|    B|\n",
      "+---+----+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sc.parallelize([\n",
    "        (1, 'a', 'A', None), \n",
    "        (2, 'a', 'B', 30.3), \n",
    "        (3, 'b', 'B', 27.8), \n",
    "        (4, 'c', None, 31.2), \n",
    "        (5, None, 'B', 32.5)]) \\\n",
    "    .toDF([\"id\", \"x1\", 'x2', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+-----+\n",
      "| id|  x1|  x2|score|\n",
      "+---+----+----+-----+\n",
      "|  1|   a|   A| null|\n",
      "|  2|   a|   B| 30.3|\n",
      "|  3|   b|   B| 27.8|\n",
      "|  4|   c|null| 31.2|\n",
      "|  5|null|   B| 32.5|\n",
      "+---+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_mode = ImputeCategoricalWithMode() \\\n",
    "    .setInputCols(['x1', 'x2']) \\\n",
    "    .setOutputCols(['x1_im', 'x2_im'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_median = Imputer(inputCols=[\"score\"], outputCols=[\"score_im\"]) \\\n",
    "    .setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(stages=[impute_mode, impute_median]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+-----+-----+-----+--------+\n",
      "| id|  x1|  x2|score|x1_im|x2_im|score_im|\n",
      "+---+----+----+-----+-----+-----+--------+\n",
      "|  1|   a|   A| null|    a|    A|    30.3|\n",
      "|  2|   a|   B| 30.3|    a|    B|    30.3|\n",
      "|  3|   b|   B| 27.8|    b|    B|    27.8|\n",
      "|  4|   c|null| 31.2|    c|    B|    31.2|\n",
      "|  5|null|   B| 32.5|    a|    B|    32.5|\n",
      "+---+----+----+-----+-----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Pipeline Model Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tmp/impute-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = PipelineModel.load('tmp/impute-pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImputeCategoricalWithModeModel_4fe986717ecaa3cd9327,\n",
       " Imputer_4bd58cecabb0b6930ac8]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+-----+-----+-----+--------+\n",
      "| id|  x1|  x2|score|x1_im|x2_im|score_im|\n",
      "+---+----+----+-----+-----+-----+--------+\n",
      "|  1|   a|   A| null|    a|    A|    30.3|\n",
      "|  2|   a|   B| 30.3|    a|    B|    30.3|\n",
      "|  3|   b|   B| 27.8|    b|    B|    27.8|\n",
      "|  4|   c|null| 31.2|    c|    B|    31.2|\n",
      "|  5|null|   B| 32.5|    a|    B|    32.5|\n",
      "+---+----+----+-----+-----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
